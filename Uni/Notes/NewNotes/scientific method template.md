---
tags:
  - lecture-slide
  - uni
course: Scientific Method
lecture: null
date: 2026-01-08
---
# Scientific Method & Research Practice – Comprehensive Notes
- [[#1. The Scientific Method|1. The Scientific Method]]
	- [[#1. The Scientific Method#Core Steps|Core Steps]]
- [[#2. Literature Search|2. Literature Search]]
- [[#3. Types of Scientific Literature|3. Types of Scientific Literature]]
- [[#4. Reading Scientific Papers|4. Reading Scientific Papers]]
- [[#5. Assessing Scientific Quality|5. Assessing Scientific Quality]]
- [[#6. Citation Metrics|6. Citation Metrics]]
- [[#7. Hypotheses in Science|7. Hypotheses in Science]]
- [[#8. Experimental Design|8. Experimental Design]]
	- [[#8. Experimental Design#Study Types|Study Types]]
- [[#9. Variables in Experiments|9. Variables in Experiments]]
- [[#10. Randomization, Control, and Blocking|10. Randomization, Control, and Blocking]]
- [[#11. Replication and Repetition|11. Replication and Repetition]]
- [[#12. Bias in Research|12. Bias in Research]]
- [[#13. Reproducible Research|13. Reproducible Research]]
- [[#14. Foundations of Statistics|14. Foundations of Statistics]]
- [[#15. Data Types and Scales|15. Data Types and Scales]]
- [[#16. Descriptive Statistics|16. Descriptive Statistics]]
- [[#17. Probability and Distributions|17. Probability and Distributions]]
- [[#18. Hypothesis Testing|18. Hypothesis Testing]]
- [[#19. Common Statistical Tests|19. Common Statistical Tests]]
- [[#20. Writing Scientific Papers|20. Writing Scientific Papers]]
- [[#21. Ethical Foundations|21. Ethical Foundations]]
- [[#22. Value Sensitive Design|22. Value Sensitive Design]]
- [[#23. Responsibility in Engineering|23. Responsibility in Engineering]]
- [[#24. Key Takeaways|24. Key Takeaways]]


---

## 1. The Scientific Method

The scientific method is a structured approach to acquiring knowledge through systematic observation, hypothesis formulation, experimentation, and analysis. It is evidence-based, transparent, and repeatable, allowing independent verification of results. Scientific inquiry builds upon previous knowledge and is designed to reduce bias and subjectivity.

### Core Steps
1. Identifying a problem or research question.
2. Reviewing existing literature and prior knowledge.
3. Formulating a testable and falsifiable hypothesis.
4. Designing and conducting experiments or observations.
5. Analyzing collected data using appropriate methods.
6. Drawing conclusions based on evidence.
7. Publishing results for peer review and replication.

---

## 2. Literature Search

A literature search is the first practical step in any scientific project. Its purpose is to understand what is already known, identify gaps in knowledge, and position new research within the existing body of work. A thorough search reduces duplication and improves research quality.

Effective search strategies include selecting appropriate keywords, using quotation marks for key phrases, analyzing references in relevant papers, and examining who cites those papers. Iteration continues until the same high-quality sources repeatedly appear, indicating sufficient coverage.

---

## 3. Types of Scientific Literature

Scientific knowledge is disseminated through various publication types. General journals target broad audiences, while specialized journals focus on narrow research areas. Conference proceedings often present early or ongoing work, while review journals summarize entire research fields. Method journals emphasize techniques rather than results. Patents protect technical inventions and are valuable sources of applied knowledge.

---

## 4. Reading Scientific Papers

Efficient reading of scientific papers involves focusing on structure rather than reading linearly. Abstracts provide a condensed overview, introductions explain motivation and context, figures summarize results, and conclusions highlight implications. Methods are consulted to assess reproducibility and validity.

Critical reading evaluates clarity of hypotheses, soundness of experimental design, appropriateness of statistical analysis, and honesty in discussing limitations.

---

## 5. Assessing Scientific Quality

Quality assessment requires more than citation counts. A good paper clearly defines its problem, follows rigorous methodology, reports reproducible results, and acknowledges limitations. High-impact journals may prioritize novelty over detail, while specialized journals often provide deeper technical explanations.

Readers must evaluate whether conclusions are supported by data and whether alternative explanations have been considered.

---

## 6. Citation Metrics

Citation metrics are numerical indicators used to assess researchers, journals, and publications. Common metrics include citation count, h-index, impact factor, eigenfactor, and article influence score. While widely used, these metrics are sensitive to database choice, self-citations, and name ambiguity.

Metrics should support—not replace—critical judgment based on content quality.

---

## 7. Hypotheses in Science

A hypothesis is a clear, testable, and falsifiable statement predicting an outcome. It provides direction for experimentation and defines what evidence would support or refute it. Good hypotheses are grounded in theory and prior evidence.

When experiments fail, researchers must reconsider experimental conditions, refine hypotheses, or question underlying assumptions.

---

## 8. Experimental Design

Experimental design determines the reliability of scientific conclusions. Well-designed experiments minimize bias and variability while isolating causal relationships.

### Study Types
- **Observational studies** collect data without manipulation and are useful for exploration.
- **Manipulative or comparative studies** actively change variables to test hypotheses.

---

## 9. Variables in Experiments

Independent variables are factors manipulated by the experimenter, while dependent variables are measured outcomes. Nuisance variables influence results unintentionally and must be controlled, minimized, or accounted for.

Clear identification and control of variables are essential for valid conclusions.

---

## 10. Randomization, Control, and Blocking

Randomization reduces the influence of unknown factors by distributing them evenly. Control groups provide a baseline for comparison. Blocking groups experimental units with similar characteristics to reduce variability caused by known nuisance factors.

These principles increase statistical power and experimental reliability.

---

## 11. Replication and Repetition

Repetition refers to multiple measurements under identical conditions, while replication involves repeating the entire experiment under different conditions or times. Replication captures real-world variability and is essential for scientific credibility.

True scientific validation occurs when independent researchers replicate findings.

---

## 12. Bias in Research

Bias introduces systematic error and threatens objectivity. Cognitive biases include confirmation bias and anchoring. Experimental biases include observer-expectancy, selection bias, and publication bias. Funding and academic pressures can also distort outcomes.

Awareness and mitigation of bias are central responsibilities of researchers.

---

## 13. Reproducible Research

Reproducibility means that experiments and analyses can be independently repeated using the same data and methods. Poor documentation, missing parameters, or selective reporting undermine reproducibility.

Reproducible research improves transparency, credibility, and long-term usability of scientific results.

---

## 14. Foundations of Statistics

Statistics provides tools for describing data and making inferences about populations from samples. Descriptive statistics summarize data, while inferential statistics test hypotheses and estimate population parameters.

Choosing appropriate statistical tools depends on data type, distribution, and study design.

---

## 15. Data Types and Scales

Data can be quantitative or qualitative and measured on nominal, ordinal, interval, or ratio scales. Understanding data types is critical for selecting valid statistical analyses.

Misclassification of data leads to incorrect conclusions.

---

## 16. Descriptive Statistics

Descriptive statistics include measures of central tendency (mean, median, mode) and variability (variance, standard deviation). Visualizations such as plots and diagrams reveal patterns, trends, and anomalies in data.

These tools provide initial insight before formal inference.

---

## 17. Probability and Distributions

Probability theory underpins statistical inference. The Central Limit Theorem states that sample means approach a normal distribution as sample size increases, regardless of original distribution. This principle enables parametric testing in many practical scenarios.

---

## 18. Hypothesis Testing

Hypothesis testing evaluates whether observed data supports or contradicts a null hypothesis. Decisions depend on test statistics, p-values, and significance levels.

Type I errors involve false positives, while Type II errors involve false negatives. Proper test design balances these risks.

---

## 19. Common Statistical Tests

Common tests include t-tests for mean comparison, ANOVA for multiple conditions, chi-squared tests for categorical data, and regression for modeling relationships. Assumptions about variance and normality must be verified before application.

---

## 20. Writing Scientific Papers

Scientific writing communicates research clearly and accurately. A standard structure ensures logical flow from motivation to conclusions. Clarity, honesty, and precision are prioritized over stylistic complexity.

Titles and abstracts serve as entry points and determine whether a paper is read.

---

## 21. Ethical Foundations

Ethics guides responsible scientific conduct. Consequentialism focuses on outcomes, deontology on rules, and virtue ethics on moral character. Ethical reasoning informs decisions beyond technical correctness.

---

## 22. Value Sensitive Design

Value Sensitive Design integrates human values into technological development. It considers stakeholders, social impacts, and technical solutions simultaneously. Ethics is treated as a design constraint rather than an afterthought.

---

## 23. Responsibility in Engineering

Engineers influence society through the technologies they create. Responsible practice includes proactive harm reduction, transparency, and public engagement. In some cases, choosing not to develop a technology is the most ethical option.

---

## 24. Key Takeaways

Good science is systematic, transparent, reproducible, and ethically grounded. Statistics support reasoning but do not replace critical thinking. Scientific responsibility extends beyond correctness to societal impact.
